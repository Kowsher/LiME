{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6004cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/mkowsher/.conda/envs/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.73s/it]\n",
      "/jet/home/mkowsher/.conda/envs/myenv/lib/python3.13/site-packages/accelerate/utils/modeling.py:1598: UserWarning: The following device_map keys do not match any submodules in the model: ['model.image_newline']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VERIFICATION:\n",
      "==================================================\n",
      "Processor image_grid_pinpoints: [[384, 384]]\n",
      "Model config image_grid_pinpoints: [[384, 384]]\n",
      "Vision config image_size: 384\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "TESTING SINGLE SAMPLES:\n",
      "==================================================\n",
      "\n",
      "Sample 0 (image):\n",
      "  input_ids: torch.Size([1509])\n",
      "  pixel_values: torch.Size([2, 3, 384, 384])\n",
      "  image_sizes: tensor([512, 512])\n",
      "\n",
      "Sample 1 (text):\n",
      "  input_ids: torch.Size([59])\n",
      "\n",
      "Sample 2 (image):\n",
      "  input_ids: torch.Size([1508])\n",
      "  pixel_values: torch.Size([2, 3, 384, 384])\n",
      "  image_sizes: tensor([512, 512])\n",
      "\n",
      "Sample 3 (video):\n",
      "  input_ids: torch.Size([1614])\n",
      "  pixel_values_videos: torch.Size([8, 3, 384, 384])\n",
      "\n",
      "Sample 4 (image):\n",
      "  input_ids: torch.Size([1525])\n",
      "  pixel_values: torch.Size([2, 3, 384, 384])\n",
      "  image_sizes: tensor([512, 512])\n",
      "\n",
      "Sample 5 (text):\n",
      "  input_ids: torch.Size([50])\n",
      "\n",
      "Sample 6 (image):\n",
      "  input_ids: torch.Size([1522])\n",
      "  pixel_values: torch.Size([2, 3, 384, 384])\n",
      "  image_sizes: tensor([32, 32])\n",
      "\n",
      "Sample 7 (text):\n",
      "  input_ids: torch.Size([83])\n",
      "\n",
      "Sample 8 (text):\n",
      "  input_ids: torch.Size([48])\n",
      "\n",
      "Sample 9 (text):\n",
      "  input_ids: torch.Size([44])\n",
      "\n",
      "Sample 10 (text):\n",
      "  input_ids: torch.Size([51])\n",
      "\n",
      "Sample 11 (video):\n",
      "  input_ids: torch.Size([1614])\n",
      "  pixel_values_videos: torch.Size([8, 3, 384, 384])\n",
      "\n",
      "==================================================\n",
      "TESTING COLLATOR:\n",
      "==================================================\n",
      "Batch keys: ['input_ids', 'attention_mask', 'labels', 'pixel_values', 'image_sizes', 'pixel_values_videos']\n",
      "  input_ids: torch.Size([4, 1614])\n",
      "  attention_mask: torch.Size([4, 1614])\n",
      "  labels: torch.Size([4, 1614])\n",
      "  pixel_values: torch.Size([4, 3, 384, 384])\n",
      "  image_sizes: torch.Size([2, 2])\n",
      "  pixel_values_videos: torch.Size([1, 8, 3, 384, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis250258p/mkowsher/dataset/MVBench/trainer.py:337: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `LiMETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BATCH TENSOR SHAPES:\n",
      "======================================================================\n",
      "input_ids: torch.Size([20, 1614]), dtype=torch.int64\n",
      "attention_mask: torch.Size([20, 1614]), dtype=torch.int64\n",
      "labels: torch.Size([20, 1614]), dtype=torch.int64\n",
      "pixel_values: torch.Size([10, 3, 384, 384]), dtype=torch.float32\n",
      "image_sizes: torch.Size([5, 2]), dtype=torch.int64\n",
      "pixel_values_videos: torch.Size([3, 8, 3, 384, 384]), dtype=torch.float32\n",
      "\n",
      "======================================================================\n",
      "SAMPLE MODALITIES:\n",
      "======================================================================\n",
      "Sample 0: image\n",
      "Sample 1: text\n",
      "Sample 2: image\n",
      "Sample 3: video\n",
      "Sample 4: image\n",
      "Sample 5: text\n",
      "Sample 6: image\n",
      "Sample 7: text\n",
      "Sample 8: text\n",
      "Sample 9: text\n",
      "Sample 10: text\n",
      "Sample 11: video\n",
      "Sample 12: text\n",
      "Sample 13: text\n",
      "Sample 14: text\n",
      "Sample 15: text\n",
      "Sample 16: video\n",
      "Sample 17: text\n",
      "Sample 18: image\n",
      "Sample 19: text\n",
      "\n",
      "Modality distribution: {'image': 5, 'text': 12, 'video': 3}\n",
      "\n",
      "======================================================================\n",
      "VISUAL DATA INFO:\n",
      "======================================================================\n",
      "pixel_values (images): torch.Size([10, 3, 384, 384])\n",
      "  - Number of image samples in batch: 5\n",
      "pixel_values_videos: torch.Size([3, 8, 3, 384, 384])\n",
      "  - Number of video samples in batch: 3\n",
      "image_sizes: torch.Size([5, 2])\n",
      "\n",
      "======================================================================\n",
      "DECODED TEXT (last 150 tokens of each sample):\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 0 | Modality: image\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "Answer the question based on the given image.\n",
      "What were these for?<|im_end|><|im_start|>assistant \n",
      "rain<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "rain<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 1 | Modality: text\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>user \n",
      "Choose the correct answer to the question.\n",
      "Skylar got a letter that said she was accepted for the executive job. How would Skylar feel afterwards?\n",
      "\n",
      "  Options: \n",
      " A. very ambitious\n",
      " B. grateful\n",
      " C. 'll be disappointed<|im_end|><|im_start|>assistant \n",
      "B<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "B<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 2 | Modality: image\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "Use the image to briefly answer the question.\n",
      "is this liquor?<|im_end|><|im_start|>assistant \n",
      "yes<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "yes<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 3 | Modality: video\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>\n",
      "Question: What tampering does this video exhibit?\n",
      "Options:\n",
      "(A) original\n",
      "(B) masking\n",
      "(C) repetition\n",
      "(D) substitution\n",
      "(E) dropping\n",
      "(F) rotate<|im_end|><|im_start|>assistant \n",
      "A<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "A<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 4 | Modality: image\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "Answer the Science question by selecting the single best option.\n",
      "Does this passage describe the weather or the climate?\n",
      "\n",
      "Options:\n",
      "A. weather\n",
      "B. climate<|im_end|><|im_start|>assistant \n",
      "B<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "B<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 5 | Modality: text\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>user \n",
      "Choose the correct answer to the question.\n",
      "Envy overtook Betty when they looked at Jessica's painting bc _ used less pigments in their painting.\n",
      "\n",
      "  Options: \n",
      " A. Betty\n",
      " B. Jessica<|im_end|><|im_start|>assistant \n",
      "A<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "A<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 6 | Modality: image\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "You are a digit classifier. Predict the SVHN digit (0‚Äì9) shown in the image and answer with a single digit.<|im_end|><|im_start|>assistant \n",
      "4<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "4<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 7 | Modality: text\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>user \n",
      "Task: Question paraphrase detection.\n",
      "Decide whether the two questions are paraphrases of each other (duplicate or not_duplicate).\n",
      "\n",
      "Sentence 1: In the context of AI, how can the following three terms be distinguished? - State Space - Search Space - Search Tree/Graph\n",
      "Sentence 2: How do I apply the breadth-first search, breadth-first searchÿü<|im_end|><|im_start|>assistant \n",
      "not_duplicate<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "not_duplicate<|im_end|>\n",
      "Label token count: 6\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 8 | Modality: text\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>user \n",
      "Choose the correct answer to the question.\n",
      "Emily cornered Carrie in the school corridor to learn more about beauty products because _ was always popular.\n",
      "\n",
      "  Options: \n",
      " A. Emily\n",
      " B. Carrie<|im_end|><|im_start|>assistant \n",
      "B<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "B<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "SAMPLE 9 | Modality: text\n",
      "======================================================================\n",
      "Last 150 tokens decoded:\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|im_start|>user \n",
      "Choose the correct answer to the question.\n",
      "I had to replace my washer instead of my dryer because the _ was older.\n",
      "\n",
      "  Options: \n",
      " A. dryer\n",
      " B. washer<|im_end|><|im_start|>assistant \n",
      "B<|im_end|>\n",
      "\n",
      "üìù LABELS (what model learns to predict):\n",
      "<|im_start|>assistant \n",
      "B<|im_end|>\n",
      "Label token count: 5\n",
      "\n",
      "======================================================================\n",
      "TOKEN-FEATURE ALIGNMENT CHECK:\n",
      "======================================================================\n",
      "Total <image> tokens in batch: 7425\n",
      "Total <video> tokens in batch: 4707\n",
      "pixel_values shape: torch.Size([10, 3, 384, 384])\n",
      "pixel_values_videos shape: torch.Size([3, 8, 3, 384, 384])\n",
      "============================================================\n",
      "LiME Model Summary\n",
      "============================================================\n",
      "PEFT Type:          lora\n",
      "LiME Layers:        216\n",
      "Total Parameters:   8,034,294,520\n",
      "Trainable:          2,444,504 (0.03%)\n",
      "Experts per Layer:  4\n",
      "Top-K:              1\n",
      "Rank:               2\n",
      "============================================================\n",
      "trainable params: 2,444,504 / 8,034,294,520\n",
      "============================================================\n",
      "Parameter Groups\n",
      "============================================================\n",
      "[MOE] 648 tensors, 1,746,136 params, lr=1.00e-03\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.LiMEs\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.LiME_shared\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.gamma\n",
      "  ... and 645 more\n",
      "[PEFT] 216 tensors, 698,368 params, lr=4.00e-04\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.B\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.B\n",
      "  - model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.B\n",
      "  ... and 213 more\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15862' max='15862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15862/15862 25:04:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.175200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.159400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.138900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.140500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.096100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.091000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15862, training_loss=0.15963918629758012, metrics={'train_runtime': 90320.8397, 'train_samples_per_second': 3.512, 'train_steps_per_second': 0.176, 'total_flos': 2.035490262486711e+19, 'train_loss': 0.15963918629758012, 'task_loss': 0.009864027611911297, 'balance_loss': 0.0005144942551851273, 'epoch': 2.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import LlavaOnevisionForConditionalGeneration, LlavaOnevisionProcessor\n",
    "from utils import MultiModalDataset, MultiModalCollator\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import av\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "\n",
    "from trainer import print_LiME_summary, LiMEArguments, LiMETrainer\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from evaluation import run_full_evaluation\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "    \n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "from LiMELoRAFA import apply_peft\n",
    "\n",
    "cache_dir = \"/ocean/projects/cis250258p/mkowsher/hf_cache\"\n",
    "model_name = \"/ocean/projects/cis250258p/mkowsher/hf_cache/llava-onevision-qwen2-7b-ov-hf\"\n",
    "save_csv=\"evaluation_results_lorafa.csv\"\n",
    "data_root=\"/ocean/projects/cis250258p/mkowsher/dataset/MVBench\"\n",
    "dataset_name=\"hf_mvbench_updated\"\n",
    "\n",
    "# Load processor\n",
    "processor = LlavaOnevisionProcessor.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# ‚≠ê CRITICAL: Set fixed resolution BEFORE using processor\n",
    "processor.image_processor.image_grid_pinpoints = [[384, 384]]\n",
    "processor.image_processor.size = {\"height\": 384, \"width\": 384}\n",
    "processor.tokenizer.padding_side = \"left\" \n",
    "\n",
    "if processor.tokenizer.pad_token is None:\n",
    "    processor.tokenizer.pad_token = processor.tokenizer.eos_token\n",
    "\n",
    "# Load model\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "\n",
    "# ‚≠ê CRITICAL: Update model config to match\n",
    "model.config.image_grid_pinpoints = [[384, 384]]\n",
    "\n",
    "# ‚≠ê VERIFY the settings\n",
    "print(\"=\"*50)\n",
    "print(\"VERIFICATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Processor image_grid_pinpoints: {processor.image_processor.image_grid_pinpoints}\")\n",
    "print(f\"Model config image_grid_pinpoints: {model.config.image_grid_pinpoints}\")\n",
    "print(f\"Vision config image_size: {model.config.vision_config.image_size}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_from_disk(dataset_name)\n",
    "\n",
    "train_dataset = MultiModalDataset(\n",
    "    dataset=dataset['train'],\n",
    "    processor=processor,\n",
    "    data_root=data_root,\n",
    "    num_video_frames=8,\n",
    "    max_length=2048,\n",
    ")\n",
    "collator = MultiModalCollator(\n",
    "    processor=processor,\n",
    "    max_length=2048,\n",
    ")\n",
    "\n",
    "# ============ TEST FIRST ============\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTING SINGLE SAMPLES:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test one of each modality\n",
    "for i in range(min(50, len(train_dataset))):\n",
    "    sample = train_dataset[i]\n",
    "    src_type = sample.get('source_type', 'unknown')\n",
    "    print(f\"\\nSample {i} ({src_type}):\")\n",
    "    print(f\"  input_ids: {sample['input_ids'].shape}\")\n",
    "    if 'pixel_values' in sample:\n",
    "        print(f\"  pixel_values: {sample['pixel_values'].shape}\")\n",
    "    if 'image_sizes' in sample:\n",
    "        print(f\"  image_sizes: {sample['image_sizes']}\")\n",
    "    if 'pixel_values_videos' in sample:\n",
    "        print(f\"  pixel_values_videos: {sample['pixel_values_videos'].shape}\")\n",
    "    \n",
    "    # Stop after finding one of each\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "# Test collator with small batch\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTING COLLATOR:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_samples = [train_dataset[i] for i in range(4)]\n",
    "test_batch = collator(test_samples)\n",
    "print(\"Batch keys:\", list(test_batch.keys()))\n",
    "for k, v in test_batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"  {k}: {v.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Collect exactly 20 samples from the PROCESSED dataset\n",
    "samples = []\n",
    "for i in range(20):\n",
    "    samples.append(train_dataset[i])  # ‚úÖ Use train_dataset, not dataset['train']\n",
    "\n",
    "# Track modalities before collating\n",
    "modalities = [s['source_type'] for s in samples]\n",
    "\n",
    "# Run through collator\n",
    "batch = collator(samples)\n",
    "\n",
    "# Inspect tensor shapes\n",
    "print(\"=\"*70)\n",
    "print(\"BATCH TENSOR SHAPES:\")\n",
    "print(\"=\"*70)\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k}: {v.shape}, dtype={v.dtype}\")\n",
    "    elif isinstance(v, list):\n",
    "        print(f\"{k}: list of {len(v)} items\")\n",
    "\n",
    "# Check modalities\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE MODALITIES:\")\n",
    "print(\"=\"*70)\n",
    "for i, mod in enumerate(modalities):\n",
    "    print(f\"Sample {i}: {mod}\")\n",
    "\n",
    "# Count by modality\n",
    "from collections import Counter\n",
    "mod_counts = Counter(modalities)\n",
    "print(f\"\\nModality distribution: {dict(mod_counts)}\")\n",
    "\n",
    "# Check visual data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUAL DATA INFO:\")\n",
    "print(\"=\"*70)\n",
    "if 'pixel_values' in batch:\n",
    "    print(f\"pixel_values (images): {batch['pixel_values'].shape}\")\n",
    "    print(f\"  - Number of image samples in batch: {modalities.count('image')}\")\n",
    "else:\n",
    "    print(\"No images in this batch\")\n",
    "\n",
    "if 'pixel_values_videos' in batch:\n",
    "    print(f\"pixel_values_videos: {batch['pixel_values_videos'].shape}\")\n",
    "    print(f\"  - Number of video samples in batch: {modalities.count('video')}\")\n",
    "else:\n",
    "    print(\"No videos in this batch\")\n",
    "\n",
    "if 'image_sizes' in batch:\n",
    "    print(f\"image_sizes: {batch['image_sizes'].shape}\")\n",
    "\n",
    "# Decode and inspect\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECODED TEXT (last 150 tokens of each sample):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(min(10, len(samples))):  # First 10 for readability\n",
    "    modality = modalities[i]\n",
    "    \n",
    "    # Get last 150 tokens\n",
    "    last_tokens = batch[\"input_ids\"][i][-150:]\n",
    "    decoded = processor.tokenizer.decode(last_tokens, skip_special_tokens=False)\n",
    "    \n",
    "    # Get labels\n",
    "    labels = batch[\"labels\"][i]\n",
    "    label_tokens = labels[labels != -100]\n",
    "    label_text = processor.tokenizer.decode(label_tokens, skip_special_tokens=False) if len(label_tokens) > 0 else \"[NO LABELS]\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SAMPLE {i} | Modality: {modality}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Last 150 tokens decoded:\\n{decoded}\")\n",
    "    print(f\"\\nüìù LABELS (what model learns to predict):\\n{label_text}\")\n",
    "    print(f\"Label token count: {len(label_tokens)}\")\n",
    "\n",
    "# Verify token-feature alignment for images\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOKEN-FEATURE ALIGNMENT CHECK:\")\n",
    "print(\"=\"*70)\n",
    "image_token_id = processor.tokenizer.convert_tokens_to_ids(\"<image>\")\n",
    "video_token_id = processor.tokenizer.convert_tokens_to_ids(\"<video>\")\n",
    "\n",
    "total_image_tokens = (batch['input_ids'] == image_token_id).sum().item()\n",
    "total_video_tokens = (batch['input_ids'] == video_token_id).sum().item()\n",
    "\n",
    "print(f\"Total <image> tokens in batch: {total_image_tokens}\")\n",
    "print(f\"Total <video> tokens in batch: {total_video_tokens}\")\n",
    "\n",
    "if 'pixel_values' in batch:\n",
    "    # For fixed 384x384, each image = 1 patch = 729 features (27x27) after pooling\n",
    "    # But depends on model config\n",
    "    print(f\"pixel_values shape: {batch['pixel_values'].shape}\")\n",
    "    \n",
    "if 'pixel_values_videos' in batch:\n",
    "    print(f\"pixel_values_videos shape: {batch['pixel_values_videos'].shape}\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "targets = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"out_proj\"]\n",
    "\n",
    "\n",
    "def lm_only_targets(path, module):\n",
    "    # Only wrap modules under model.language_model\n",
    "    if not path.startswith(\"model.language_model.\"):\n",
    "        return False\n",
    "\n",
    "    # Expect paths like: model.language_model.layers.<idx>.*\n",
    "    if \".layers.\" not in path:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        layer_id = int(path.split(\".layers.\")[1].split(\".\")[0])\n",
    "    except (IndexError, ValueError):\n",
    "        return False\n",
    "\n",
    "\n",
    "    return any(path.endswith(name) for name in targets)\n",
    "\n",
    "model = apply_peft(\n",
    "    model,\n",
    "    targets=targets,\n",
    "    num_experts=4,\n",
    "    rank=2,\n",
    "    use_shared_LiME=True,\n",
    "    n_gram=2,\n",
    "    top_k=1,\n",
    "    rep_mode=\"token\",\n",
    "    jitter_noise=0.1,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    temperature=0.5,\n",
    "    gamma_routing = 0.7, \n",
    "    auto_topk=True, \n",
    "    auto_topk_threshold=0.5, \n",
    "    peft_dtype=torch.float32,   # A, B in float32\n",
    "    moe_dtype=torch.float32,    # moe3s, gamma in float32\n",
    "\n",
    ")\n",
    "\n",
    "print_LiME_summary(model)\n",
    "\n",
    "# 1) Count params that require grad\n",
    "trainable = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "total = sum(p.numel() for _, p in model.named_parameters())\n",
    "trainable_num = sum(p.numel() for _, p in trainable)\n",
    "print(f\"trainable params: {trainable_num:,} / {total:,}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "training_args = LiMEArguments(\n",
    "    output_dir=\"./llava-lora-finetuned\",\n",
    "    per_device_train_batch_size=5,\n",
    "    gradient_accumulation_steps=4,  \n",
    "    save_total_limit=2,\n",
    "    save_steps=500000,\n",
    "    num_train_epochs=2,\n",
    "    bf16=True,  \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    remove_unused_columns=False, \n",
    "\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,          # makes it print log lines instead of tqdm bar behavior\n",
    "    #log_level=\"info\",\n",
    "    #logging_first_step=True,\n",
    "    moe_lr=1e-3,          # For propulsions, gamma (float32)\n",
    "    peft_lr=4e-4,         # For LoRA A/B (float32)\n",
    "    importance_coef=0.1,\n",
    "    kl_coef=0.01,\n",
    "  \n",
    ")\n",
    "\n",
    "# Also make sure model doesn't have it enabled\n",
    "model.gradient_checkpointing_disable()  # ‚≠ê Call this explicitly\n",
    "\n",
    "\n",
    "\n",
    "# Example instantiation:\n",
    "trainer = LiMETrainer(\n",
    "    model=model,\n",
    "    args=training_args,                  # your HF TrainingArguments\n",
    "    train_dataset=train_dataset,\n",
    "\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=collator,  # ‚úÖ Custom collator dynamically pads batch sequences\n",
    "\n",
    "\n",
    ")\n",
    "trainer.train() \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431e5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVALUATION: 47 splits, 1000 samples each, batch_size=6\n",
      "Numeric tolerance: 0.5\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_chartqa (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_chartqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [03:20<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_chartqa: 750/1000 = 75.00%\n",
      "   Match types: {'no_match': 250, 'exact': 688, 'numeric': 58, 'contains': 4}\n",
      "   ‚ùå True: '15.84' | Pred: '15.09' | Raw: '15.09' \n",
      "   ‚úÖ True: '146' | Pred: '146' | Raw: '146' [exact]\n",
      "   ‚ùå True: '10.37' | Pred: '11.32' | Raw: '11.32' \n",
      "   ‚ùå True: '14722.84' | Pred: '14738.81' | Raw: '14738.81' \n",
      "   ‚úÖ True: '75.82' | Pred: '75.82' | Raw: '75.82' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_okvqa (841 samples, batch_size=6)\n",
      "Task type: multiple_choice, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_okvqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [02:20<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_okvqa: 489/841 = 58.15%\n",
      "   Match types: {'exact': 464, 'no_match': 352, 'contains': 24, 'numeric': 1}\n",
      "   ‚úÖ True: 'river' | Pred: 'river' | Raw: 'river' [exact]\n",
      "   ‚ùå True: 'carlo collodi' | Pred: 'gustave' | Raw: 'gustave flaubert' \n",
      "   ‚ùå True: '1936' | Pred: '1938' | Raw: '1938' \n",
      "   ‚úÖ True: 'airplane' | Pred: 'airplane' | Raw: 'airplane' [exact]\n",
      "   ‚úÖ True: 'recreational' | Pred: 'recreational' | Raw: 'recreational' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_scienceqa (518 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_scienceqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [01:05<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_scienceqa: 509/518 = 98.26%\n",
      "   Match types: {'exact': 509, 'no_match': 9}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_seed_bench (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_seed_bench: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [01:02<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_seed_bench: 382/500 = 76.40%\n",
      "   Match types: {'exact': 382, 'no_match': 118}\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_text_recognition (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_text_recognition: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [02:35<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_text_recognition: 882/1000 = 88.20%\n",
      "   Match types: {'no_match': 118, 'exact': 874, 'contains': 8}\n",
      "   ‚ùå True: 'exhibicionismus' | Pred: 'exhibicionisms' | Raw: 'EXHIBICIONISMS' \n",
      "   ‚úÖ True: 'delikatesem' | Pred: 'delikatesem' | Raw: 'Delikatesem' [exact]\n",
      "   ‚úÖ True: 'vydojme' | Pred: 'vydojme' | Raw: 'Vydojme' [exact]\n",
      "   ‚úÖ True: 'odlepena' | Pred: 'odlepena' | Raw: 'Odlepena' [exact]\n",
      "   ‚úÖ True: 'normuj' | Pred: 'normuj' | Raw: 'normuj' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_textvqa (1000 samples, batch_size=6)\n",
      "Task type: multiple_choice, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_textvqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [02:57<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_textvqa: 721/1000 = 72.10%\n",
      "   Match types: {'no_match': 279, 'exact': 628, 'contains': 75, 'numeric': 18}\n",
      "   ‚ùå True: '32' | Pred: '22' | Raw: '22' \n",
      "   ‚úÖ True: 'sopko' | Pred: 'sopko' | Raw: 'sopko' [exact]\n",
      "   ‚úÖ True: '1970' | Pred: '1970' | Raw: '1970' [exact]\n",
      "   ‚úÖ True: 'over burning witches' | Pred: 'over burning witches' | Raw: 'over burning witches' [exact]\n",
      "   ‚úÖ True: 'go' | Pred: 'go' | Raw: 'go' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_vizwiz_vqa (417 samples, batch_size=6)\n",
      "Task type: multiple_choice, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_vizwiz_vqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [01:15<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_vizwiz_vqa: 287/417 = 68.82%\n",
      "   Match types: {'exact': 239, 'no_match': 130, 'contains': 46, 'numeric': 2}\n",
      "   ‚úÖ True: 'silver' | Pred: 'silver' | Raw: 'silver' [exact]\n",
      "   ‚úÖ True: 'pink' | Pred: 'pink' | Raw: 'pink' [exact]\n",
      "   ‚úÖ True: 'street' | Pred: 'street' | Raw: 'street' [exact]\n",
      "   ‚ùå True: 'minnie riperton' | Pred: 'minette' | Raw: 'minette reperion' \n",
      "   ‚ùå True: 'andes mints' | Pred: 'cd' | Raw: 'cd case' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_vqa_rad (200 samples, batch_size=6)\n",
      "Task type: multiple_choice, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_vqa_rad: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:24<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_vqa_rad: 166/200 = 83.00%\n",
      "   Match types: {'exact': 166, 'no_match': 34}\n",
      "   ‚úÖ True: 'false' | Pred: 'false' | Raw: 'no' [exact]\n",
      "   ‚úÖ True: 'false' | Pred: 'false' | Raw: 'no' [exact]\n",
      "   ‚ùå True: 'true' | Pred: 'false' | Raw: 'no' \n",
      "   ‚úÖ True: 'true' | Pred: 'true' | Raw: 'yes' [exact]\n",
      "   ‚ùå True: 'false' | Pred: 'true' | Raw: 'yes' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_caltech101 (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_caltech101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [01:09<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_caltech101: 481/500 = 96.20%\n",
      "   Match types: {'exact': 473, 'contains': 8, 'no_match': 19}\n",
      "   ‚úÖ True: 'trilobite' | Pred: 'trilobite' | Raw: 'trilobite' [exact]\n",
      "   ‚úÖ True: 'inline skate' | Pred: 'inline skate' | Raw: 'inline skate' [exact]\n",
      "   ‚úÖ True: 'emu' | Pred: 'emu' | Raw: 'emu' [exact]\n",
      "   ‚úÖ True: 'wild cat' | Pred: 'wild cat' | Raw: 'wild cat' [exact]\n",
      "   ‚úÖ True: 'inline skate' | Pred: 'inline skate' | Raw: 'inline skate' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_eurosat (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_eurosat: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [01:04<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_eurosat: 479/500 = 95.80%\n",
      "   Match types: {'exact': 479, 'no_match': 21}\n",
      "   ‚úÖ True: 'forest' | Pred: 'forest' | Raw: 'Forest' [exact]\n",
      "   ‚úÖ True: 'forest' | Pred: 'forest' | Raw: 'Forest' [exact]\n",
      "   ‚úÖ True: 'forest' | Pred: 'forest' | Raw: 'Forest' [exact]\n",
      "   ‚úÖ True: 'forest' | Pred: 'forest' | Raw: 'Forest' [exact]\n",
      "   ‚úÖ True: 'forest' | Pred: 'forest' | Raw: 'Forest' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_flowers102 (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_flowers102: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [01:22<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_flowers102: 477/500 = 95.40%\n",
      "   Match types: {'exact': 477, 'no_match': 23}\n",
      "   ‚úÖ True: 'petunia' | Pred: 'petunia' | Raw: 'petunia' [exact]\n",
      "   ‚úÖ True: 'petunia' | Pred: 'petunia' | Raw: 'petunia' [exact]\n",
      "   ‚úÖ True: 'passion flower' | Pred: 'passion flower' | Raw: 'passion flower' [exact]\n",
      "   ‚úÖ True: 'passion flower' | Pred: 'passion flower' | Raw: 'passion flower' [exact]\n",
      "   ‚úÖ True: 'petunia' | Pred: 'petunia' | Raw: 'petunia' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_pets (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_pets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [01:21<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_pets: 483/500 = 96.60%\n",
      "   Match types: {'exact': 481, 'no_match': 17, 'contains': 2}\n",
      "   ‚úÖ True: 'leonberger' | Pred: 'leonberger' | Raw: 'leonberger' [exact]\n",
      "   ‚úÖ True: 'leonberger' | Pred: 'leonberger' | Raw: 'leonberger' [exact]\n",
      "   ‚úÖ True: 'leonberger' | Pred: 'leonberger' | Raw: 'leonberger' [exact]\n",
      "   ‚úÖ True: 'leonberger' | Pred: 'leonberger' | Raw: 'leonberger' [exact]\n",
      "   ‚úÖ True: 'leonberger' | Pred: 'leonberger' | Raw: 'leonberger' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_svhn (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_svhn: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:54<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_svhn: 475/500 = 95.00%\n",
      "   Match types: {'exact': 475, 'no_match': 25}\n",
      "   ‚úÖ True: '1' | Pred: '1' | Raw: '1' [exact]\n",
      "   ‚úÖ True: '1' | Pred: '1' | Raw: '1' [exact]\n",
      "   ‚úÖ True: '1' | Pred: '1' | Raw: '1' [exact]\n",
      "   ‚úÖ True: '1' | Pred: '1' | Raw: '1' [exact]\n",
      "   ‚úÖ True: '1' | Pred: '1' | Raw: '1' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: image_test_camelyon (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_test_camelyon: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:57<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä image_test_camelyon: 438/500 = 87.60%\n",
      "   Match types: {'exact': 438, 'no_match': 62}\n",
      "   ‚úÖ True: 'tumor' | Pred: 'tumor' | Raw: 'tumor' [exact]\n",
      "   ‚úÖ True: 'tumor' | Pred: 'tumor' | Raw: 'tumor' [exact]\n",
      "   ‚úÖ True: 'tumor' | Pred: 'tumor' | Raw: 'tumor' [exact]\n",
      "   ‚úÖ True: 'tumor' | Pred: 'tumor' | Raw: 'tumor' [exact]\n",
      "   ‚ùå True: 'tumor' | Pred: 'normal' | Raw: 'normal' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_arc_challenge (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_arc_challenge: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:11<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_arc_challenge: 443/500 = 88.60%\n",
      "   Match types: {'exact': 443, 'no_match': 57}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'b' | Raw: 'B' \n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'b' | Raw: 'B' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_arc_easy (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_arc_easy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:11<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_arc_easy: 471/500 = 94.20%\n",
      "   Match types: {'exact': 471, 'no_match': 29}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_boolq (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_boolq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:22<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_boolq: 721/1000 = 72.10%\n",
      "   Match types: {'no_match': 279, 'exact': 721}\n",
      "   ‚ùå True: 'b' | Pred: 'a' | Raw: 'A' \n",
      "   ‚ùå True: 'a' | Pred: 'b' | Raw: 'B' \n",
      "   ‚ùå True: 'a' | Pred: 'b' | Raw: 'B' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_hellaswag (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_hellaswag: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:23<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_hellaswag: 881/1000 = 88.10%\n",
      "   Match types: {'no_match': 119, 'exact': 881}\n",
      "   ‚ùå True: 'd' | Pred: 'b' | Raw: 'B' \n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'a' | Raw: 'A' \n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_openbookqa (500 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_openbookqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:11<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_openbookqa: 448/500 = 89.60%\n",
      "   Match types: {'exact': 448, 'no_match': 52}\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_piqa (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_piqa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:22<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_piqa: 874/1000 = 87.40%\n",
      "   Match types: {'exact': 874, 'no_match': 126}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_social_i_qa (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_social_i_qa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:22<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_social_i_qa: 807/1000 = 80.70%\n",
      "   Match types: {'exact': 807, 'no_match': 193}\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'b' | Pred: 'c' | Raw: 'C' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: text_test_winogrande (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_test_winogrande: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:22<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä text_test_winogrande: 821/1000 = 82.10%\n",
      "   Match types: {'exact': 821, 'no_match': 179}\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'a' | Pred: 'b' | Raw: 'B' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_sst2 (872 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_sst2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:19<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_sst2: 827/872 = 94.84%\n",
      "   Match types: {'exact': 827, 'no_match': 45}\n",
      "   ‚úÖ True: 'positive' | Pred: 'positive' | Raw: 'positive' [exact]\n",
      "   ‚úÖ True: 'negative' | Pred: 'negative' | Raw: 'negative' [exact]\n",
      "   ‚úÖ True: 'positive' | Pred: 'positive' | Raw: 'positive' [exact]\n",
      "   ‚úÖ True: 'positive' | Pred: 'positive' | Raw: 'positive' [exact]\n",
      "   ‚úÖ True: 'negative' | Pred: 'negative' | Raw: 'negative' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_qnli (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_qnli: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:55<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_qnli: 946/1000 = 94.60%\n",
      "   Match types: {'exact': 946, 'no_match': 54}\n",
      "   ‚úÖ True: 'entailment' | Pred: 'entailment' | Raw: 'entailment' [exact]\n",
      "   ‚úÖ True: 'not_entailment' | Pred: 'not_entailment' | Raw: 'not_entailment' [exact]\n",
      "   ‚ùå True: 'not_entailment' | Pred: 'entailment' | Raw: 'entailment' \n",
      "   ‚úÖ True: 'entailment' | Pred: 'entailment' | Raw: 'entailment' [exact]\n",
      "   ‚úÖ True: 'not_entailment' | Pred: 'not_entailment' | Raw: 'not_entailment' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_qqp (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_qqp: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:33<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_qqp: 861/1000 = 86.10%\n",
      "   Match types: {'exact': 861, 'no_match': 139}\n",
      "   ‚úÖ True: 'not_duplicate' | Pred: 'not_duplicate' | Raw: 'not_duplicate' [exact]\n",
      "   ‚úÖ True: 'not_duplicate' | Pred: 'not_duplicate' | Raw: 'not_duplicate' [exact]\n",
      "   ‚úÖ True: 'duplicate' | Pred: 'duplicate' | Raw: 'duplicate' [exact]\n",
      "   ‚úÖ True: 'not_duplicate' | Pred: 'not_duplicate' | Raw: 'not_duplicate' [exact]\n",
      "   ‚úÖ True: 'not_duplicate' | Pred: 'not_duplicate' | Raw: 'not_duplicate' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_cola (1000 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_cola: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:22<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_cola: 691/1000 = 69.10%\n",
      "   Match types: {'exact': 691, 'no_match': 309}\n",
      "   ‚úÖ True: 'acceptable' | Pred: 'acceptable' | Raw: 'acceptable' [exact]\n",
      "   ‚úÖ True: 'acceptable' | Pred: 'acceptable' | Raw: 'acceptable' [exact]\n",
      "   ‚úÖ True: 'acceptable' | Pred: 'acceptable' | Raw: 'acceptable' [exact]\n",
      "   ‚úÖ True: 'acceptable' | Pred: 'acceptable' | Raw: 'acceptable' [exact]\n",
      "   ‚ùå True: 'unacceptable' | Pred: 'acceptable' | Raw: 'acceptable' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_mrpc (408 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_mrpc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68/68 [00:17<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_mrpc: 359/408 = 87.99%\n",
      "   Match types: {'exact': 359, 'no_match': 49}\n",
      "   ‚úÖ True: 'equivalent' | Pred: 'equivalent' | Raw: 'equivalent' [exact]\n",
      "   ‚úÖ True: 'not_equivalent' | Pred: 'not_equivalent' | Raw: 'not_equivalent' [exact]\n",
      "   ‚úÖ True: 'not_equivalent' | Pred: 'not_equivalent' | Raw: 'not_equivalent' [exact]\n",
      "   ‚úÖ True: 'equivalent' | Pred: 'equivalent' | Raw: 'equivalent' [exact]\n",
      "   ‚úÖ True: 'not_equivalent' | Pred: 'not_equivalent' | Raw: 'not_equivalent' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: glue_test_stsb (1000 samples, batch_size=6)\n",
      "Task type: regression, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glue_test_stsb: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [03:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä glue_test_stsb:\n",
      "   Pearson:  0.9196\n",
      "   Spearman: 0.9213\n",
      "   Close (¬±0.5): 610/1000 = 61.00%\n",
      "   ‚úÖ True: 5.00 | Pred: 5.00 | Raw: '5.0'\n",
      "   ‚ùå True: 4.75 | Pred: 4.00 | Raw: '4.0'\n",
      "   ‚úÖ True: 5.00 | Pred: 5.00 | Raw: '5.0'\n",
      "   ‚úÖ True: 2.40 | Pred: 2.00 | Raw: '2.0'\n",
      "   ‚ùå True: 2.75 | Pred: 2.20 | Raw: '2.200000047683716'\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_action_sequence (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_action_sequence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:57<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_action_sequence: 107/300 = 35.67%\n",
      "   Match types: {'exact': 107, 'no_match': 193}\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚ùå True: 'e' | Pred: 'c' | Raw: 'C' \n",
      "   ‚ùå True: 'c' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'e' | Pred: 'c' | Raw: 'C' \n",
      "   ‚úÖ True: 'e' | Pred: 'e' | Raw: 'E' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_action_prediction (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_action_prediction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_action_prediction: 103/300 = 34.33%\n",
      "   Match types: {'no_match': 197, 'exact': 103}\n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_action_antonym (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_action_antonym: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:04<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_action_antonym: 212/300 = 70.67%\n",
      "   Match types: {'no_match': 88, 'exact': 212}\n",
      "   ‚ùå True: 'e' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "   ‚ùå True: 'e' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_fine_grained_action (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_fine_grained_action: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:19<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_fine_grained_action: 217/300 = 72.33%\n",
      "   Match types: {'exact': 217, 'no_match': 83}\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'e' | Raw: 'E' \n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'e' | Raw: 'E' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_unexpected_action (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_unexpected_action: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [07:41<00:00,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_unexpected_action: 145/300 = 48.33%\n",
      "   Match types: {'no_match': 155, 'exact': 145}\n",
      "   ‚ùå True: 'b' | Pred: 'e' | Raw: 'E' \n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_object_existence (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_object_existence: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:04<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_object_existence: 268/300 = 89.33%\n",
      "   Match types: {'no_match': 32, 'exact': 268}\n",
      "   ‚ùå True: 'e' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_object_interaction (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_object_interaction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:44<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_object_interaction: 91/300 = 30.33%\n",
      "   Match types: {'no_match': 209, 'exact': 91}\n",
      "   ‚ùå True: 'c' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'c' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "   ‚ùå True: 'b' | Pred: 'e' | Raw: 'E' \n",
      "   ‚ùå True: 'f' | Pred: 'e' | Raw: 'E' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_object_shuffle (300 samples, batch_size=6)\n",
      "Task type: multiple_choice, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_object_shuffle: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [10:32<00:00, 12.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_object_shuffle: 99/300 = 33.00%\n",
      "   Match types: {'no_match': 201, 'exact': 99}\n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'b' | Pred: 'd' | Raw: 'D' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_moving_direction (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_moving_direction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:05<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_moving_direction: 266/300 = 88.67%\n",
      "   Match types: {'exact': 266, 'no_match': 34}\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'e' | Pred: 'e' | Raw: 'E' [exact]\n",
      "   ‚úÖ True: 'e' | Pred: 'e' | Raw: 'E' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_action_localization (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_action_localization: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:06<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_action_localization: 104/300 = 34.67%\n",
      "   Match types: {'exact': 104, 'no_match': 196}\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚ùå True: 'd' | Pred: 'c' | Raw: 'C' \n",
      "   ‚ùå True: 'e' | Pred: 'b' | Raw: 'B' \n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_scene_transition (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_scene_transition: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:35<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_scene_transition: 75/300 = 25.00%\n",
      "   Match types: {'no_match': 225, 'exact': 75}\n",
      "   ‚ùå True: 'a' | Pred: 'c' | Raw: 'C' \n",
      "   ‚ùå True: 'f' | Pred: 'a' | Raw: 'A' \n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚ùå True: 'e' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'a' | Pred: 'd' | Raw: 'D' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_action_count (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_action_count: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [09:34<00:00, 11.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_action_count: 101/300 = 33.67%\n",
      "   Match types: {'exact': 101, 'no_match': 199}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚ùå True: 'b' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_moving_count (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_moving_count: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:04<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_moving_count: 261/300 = 87.00%\n",
      "   Match types: {'exact': 261, 'no_match': 39}\n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_moving_attribute (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_moving_attribute: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_moving_attribute: 264/300 = 88.00%\n",
      "   Match types: {'exact': 264, 'no_match': 36}\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_state_change (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_state_change: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [10:19<00:00, 12.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_state_change: 108/300 = 36.00%\n",
      "   Match types: {'exact': 108, 'no_match': 192}\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'c' | Pred: 'c' | Raw: 'C' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'd' | Raw: 'D' \n",
      "   ‚ùå True: 'f' | Pred: 'd' | Raw: 'D' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_character_order (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_character_order: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [10:23<00:00, 12.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_character_order: 96/300 = 32.00%\n",
      "   Match types: {'no_match': 204, 'exact': 96}\n",
      "   ‚ùå True: 'b' | Pred: 'e' | Raw: 'E' \n",
      "   ‚ùå True: 'b' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'c' | Pred: 'a' | Raw: 'A' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_egocentric_navigation (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_egocentric_navigation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:57<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_egocentric_navigation: 187/300 = 62.33%\n",
      "   Match types: {'no_match': 113, 'exact': 187}\n",
      "   ‚ùå True: 'e' | Pred: 'd' | Raw: 'D' \n",
      "   ‚úÖ True: 'e' | Pred: 'e' | Raw: 'E' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "   ‚úÖ True: 'b' | Pred: 'b' | Raw: 'B' [exact]\n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_episodic_reasoning (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_episodic_reasoning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:41<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_episodic_reasoning: 93/300 = 31.00%\n",
      "   Match types: {'no_match': 207, 'exact': 93}\n",
      "   ‚ùå True: 'c' | Pred: 'e' | Raw: 'E' \n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚úÖ True: 'a' | Pred: 'a' | Raw: 'A' [exact]\n",
      "   ‚ùå True: 'f' | Pred: 'b' | Raw: 'B' \n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "\n",
      "======================================================================\n",
      "Evaluating: video_test_counterfactual_inference (300 samples, batch_size=6)\n",
      "Task type: classification, Numeric tolerance: 0.5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_test_counterfactual_inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:03<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä video_test_counterfactual_inference: 261/300 = 87.00%\n",
      "   Match types: {'exact': 261, 'no_match': 39}\n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚úÖ True: 'd' | Pred: 'd' | Raw: 'D' [exact]\n",
      "   ‚ùå True: 'd' | Pred: 'e' | Raw: 'E' \n",
      "   ‚úÖ True: 'f' | Pred: 'f' | Raw: 'F' [exact]\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìÅ GLUE_TEST:\n",
      "   Classification: 3684/4280 = 86.07%\n",
      "     - glue_test_sst2: 94.84%\n",
      "     - glue_test_qnli: 94.60%\n",
      "     - glue_test_qqp: 86.10%\n",
      "     - glue_test_cola: 69.10%\n",
      "     - glue_test_mrpc: 87.99%\n",
      "   Regression: Pearson=0.9196, Spearman=0.9213\n",
      "     - glue_test_stsb: Pearson=0.9196, Spearman=0.9213\n",
      "\n",
      "üìÅ IMAGE_TEST:\n",
      "   Classification: 7019/8476 = 82.81%\n",
      "     - image_test_chartqa: 75.00%\n",
      "     - image_test_okvqa: 58.15%\n",
      "     - image_test_scienceqa: 98.26%\n",
      "     - image_test_seed_bench: 76.40%\n",
      "     - image_test_text_recognition: 88.20%\n",
      "     - image_test_textvqa: 72.10%\n",
      "     - image_test_vizwiz_vqa: 68.82%\n",
      "     - image_test_vqa_rad: 83.00%\n",
      "     - image_test_caltech101: 96.20%\n",
      "     - image_test_eurosat: 95.80%\n",
      "     - image_test_flowers102: 95.40%\n",
      "     - image_test_pets: 96.60%\n",
      "     - image_test_svhn: 95.00%\n",
      "     - image_test_camelyon: 87.60%\n",
      "\n",
      "üìÅ TEXT_TEST:\n",
      "   Classification: 5466/6500 = 84.09%\n",
      "     - text_test_arc_challenge: 88.60%\n",
      "     - text_test_arc_easy: 94.20%\n",
      "     - text_test_boolq: 72.10%\n",
      "     - text_test_hellaswag: 88.10%\n",
      "     - text_test_openbookqa: 89.60%\n",
      "     - text_test_piqa: 87.40%\n",
      "     - text_test_social_i_qa: 80.70%\n",
      "     - text_test_winogrande: 82.10%\n",
      "\n",
      "üìÅ VIDEO_TEST:\n",
      "   Classification: 3058/5700 = 53.65%\n",
      "     - video_test_action_sequence: 35.67%\n",
      "     - video_test_action_prediction: 34.33%\n",
      "     - video_test_action_antonym: 70.67%\n",
      "     - video_test_fine_grained_action: 72.33%\n",
      "     - video_test_unexpected_action: 48.33%\n",
      "     - video_test_object_existence: 89.33%\n",
      "     - video_test_object_interaction: 30.33%\n",
      "     - video_test_object_shuffle: 33.00%\n",
      "     - video_test_moving_direction: 88.67%\n",
      "     - video_test_action_localization: 34.67%\n",
      "     - video_test_scene_transition: 25.00%\n",
      "     - video_test_action_count: 33.67%\n",
      "     - video_test_moving_count: 87.00%\n",
      "     - video_test_moving_attribute: 88.00%\n",
      "     - video_test_state_change: 36.00%\n",
      "     - video_test_character_order: 32.00%\n",
      "     - video_test_egocentric_navigation: 62.33%\n",
      "     - video_test_episodic_reasoning: 31.00%\n",
      "     - video_test_counterfactual_inference: 87.00%\n",
      "\n",
      "üéØ OVERALL ACCURACY: 19227/24956 = 77.04%\n",
      "   Match breakdown: {'no_match': 5729, 'exact': 18981, 'numeric': 79, 'contains': 167}\n",
      "üéØ OVERALL CORRELATION: Pearson=0.9196, Spearman=0.9213\n",
      "\n",
      "üíæ Results saved to: evaluation_results_lorafa.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation import run_full_evaluation\n",
    "results = run_full_evaluation(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    dataset=dataset,\n",
    "    data_root=data_root,\n",
    "    num_samples_per_split=1000,\n",
    "    batch_size=6,\n",
    "    max_new_tokens=50, \n",
    "    save_csv=save_csv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21908b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
